{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_bert_classification_tpu_20newsgroup.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarmilaupadhyaya/BERT-applications/blob/master/keras_bert_classification_tpu_20newsgroup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doNFRjPqiBhM",
        "colab_type": "code",
        "outputId": "7ac205d3-f694-4f58-9d73-15ce36bf0c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#Installing keras-bert and keras adapter\n",
        "!pip install -q keras-bert keras-rectified-adam\n",
        "!wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip -o uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzoFRUGmh6a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "\n",
        "SEQ_LEN = 128\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 7\n",
        "LR = 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQ8UtquieFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pretrained model path\n",
        "import os\n",
        "\n",
        "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
        "\n",
        "# TF_KERAS must be added to environment variables in order to use TPU\n",
        "os.environ['TF_KERAS'] = '1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGzsxkLTpRrs",
        "colab_type": "code",
        "outputId": "7a3844fa-1c4f-4021-ad45-77c3a1772a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "# Initialize TPU strategy\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras_bert import get_custom_objects\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Initializing the TPU system.\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.72.174.194:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2403390728477379715)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6228598844855914428)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16572767961131503332)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3481839308587202469)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 10308478770585051711)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5360942145062977509)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12931050077123427212)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7700100961269258401)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14372083158791655833)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 16575633744267588081)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 998316912147470978)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVTPNxOyj4HJ",
        "colab_type": "code",
        "outputId": "8cd1c134-7a5c-47a8-91b6-99df87780022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# load bert model\n",
        "import codecs\n",
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "token_dict = {}\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "\n",
        "with strategy.scope():\n",
        "    model = load_trained_model_from_checkpoint(\n",
        "        config_path,\n",
        "        checkpoint_path,\n",
        "        training=True,\n",
        "        trainable=True,\n",
        "        seq_len=SEQ_LEN,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8FTPuMBXbaP",
        "colab_type": "code",
        "outputId": "f97930b8-5d80-4dee-9f13-cab87f91318b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 23440896    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "MLM-Dense (Dense)               (None, 128, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MLM-Norm (LayerNormalization)   (None, 128, 768)     1536        MLM-Dense[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MLM-Sim (EmbeddingSimilarity)   (None, 128, 30522)   30522       MLM-Norm[0][0]                   \n",
            "                                                                 Embedding-Token[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Masked (InputLayer)       [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "MLM (Masked)                    (None, 128, 30522)   0           MLM-Sim[0][0]                    \n",
            "                                                                 Input-Masked[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,811,516\n",
            "Trainable params: 109,811,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xioN-O_vtztC",
        "colab_type": "code",
        "outputId": "4e018d9c-8a2a-444b-9cc0-93cda2c01069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# load 20newsgroup dataset\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"20news-18828.tar.gz\", \n",
        "    origin=\"http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz\", \n",
        "    extract=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz\n",
            "14671872/14666916 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOFN-MIQUHhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting set of labels and index\n",
        "datapath = \".\".join(dataset.split(\".\")[:-2])\n",
        "txtfiles = os.listdir(datapath)\n",
        "labels = [(x, i) for i,x in enumerate(txtfiles)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfC3Nh8pnckd",
        "colab_type": "code",
        "outputId": "ea6fc41c-583f-426d-baf1-732e4fa505df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# prepare data as numpy array and split to test and train\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras_bert import Tokenizer\n",
        "import pandas as pd\n",
        "\n",
        "tokenizer = Tokenizer(token_dict)\n",
        "\n",
        "\n",
        "def load_data(path, labels):\n",
        "    global tokenizer\n",
        "    indices, sentiments = [], []\n",
        "    for folder, sentiment in labels:\n",
        "        folder = os.path.join(path, folder)\n",
        "        for name in tqdm(os.listdir(folder)):\n",
        "            with open(os.path.join(folder, name), 'r', encoding=\"utf-8\", errors='ignore') as reader:\n",
        "                  text = reader.read()\n",
        "            ids, segments = tokenizer.encode(text, max_len=SEQ_LEN)\n",
        "            indices.append(ids)\n",
        "            sentiments.append(sentiment)\n",
        "    items = list(zip(indices, sentiments))\n",
        "    \n",
        "    np.random.shuffle(items)\n",
        "    test_items = items[int(0.8*len(items)):]\n",
        "    train_items = items[:int(0.8*len(items))]\n",
        "    indices_test, sentiments_test = zip(*test_items)\n",
        "    indices_train, sentiments_train = zip(*train_items)\n",
        "    indices_train = np.array(indices_train)\n",
        "    indices_test = np.array(indices_test)\n",
        "    mod_train = indices_train.shape[0] % BATCH_SIZE\n",
        "    mod_test = indices_test.shape[0] % BATCH_SIZE\n",
        "    if mod_train > 0:\n",
        "        indices_train, sentiments_train = indices_train[:-mod_train], sentiments_train[:-mod_train]\n",
        "    if mod_test > 0:\n",
        "      indices_test, sentiments_test = indices_test[:-mod_test], sentiments_test[:-mod_test]\n",
        "\n",
        "    return [indices_train, np.zeros_like(indices_train)], np.array(sentiments_train),[indices_test, np.zeros_like(indices_test)], np.array(sentiments_test)\n",
        "  \n",
        "  \n",
        "\n",
        "train_path = os.path.join(os.path.dirname(dataset), '20news-18828')\n",
        "\n",
        "\n",
        "train_x, train_y, test_x, test_y = load_data(train_path, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 973/973 [00:03<00:00, 272.76it/s]\n",
            "100%|██████████| 775/775 [00:04<00:00, 179.11it/s]\n",
            "100%|██████████| 997/997 [00:05<00:00, 197.85it/s]\n",
            "100%|██████████| 980/980 [00:04<00:00, 242.97it/s]\n",
            "100%|██████████| 990/990 [00:02<00:00, 352.43it/s]\n",
            "100%|██████████| 999/999 [00:03<00:00, 269.50it/s]\n",
            "100%|██████████| 985/985 [00:04<00:00, 203.30it/s]\n",
            "100%|██████████| 910/910 [00:04<00:00, 219.32it/s]\n",
            "100%|██████████| 961/961 [00:02<00:00, 420.81it/s]\n",
            "100%|██████████| 990/990 [00:04<00:00, 245.60it/s]\n",
            "100%|██████████| 982/982 [00:02<00:00, 375.30it/s]\n",
            "100%|██████████| 799/799 [00:03<00:00, 173.61it/s]\n",
            "100%|██████████| 987/987 [00:03<00:00, 257.19it/s]\n",
            "100%|██████████| 628/628 [00:02<00:00, 220.42it/s]\n",
            "100%|██████████| 940/940 [00:06<00:00, 155.46it/s]\n",
            "100%|██████████| 994/994 [00:02<00:00, 380.74it/s]\n",
            "100%|██████████| 994/994 [00:02<00:00, 344.07it/s]\n",
            "100%|██████████| 981/981 [00:02<00:00, 371.64it/s]\n",
            "100%|██████████| 991/991 [00:04<00:00, 227.07it/s]\n",
            "100%|██████████| 972/972 [00:02<00:00, 485.24it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6go9hLYAV3sQ",
        "colab_type": "code",
        "outputId": "dcb14da4-1f1b-4f4f-ed2b-a6740dc93c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "\n",
        "pd.Series(test_y).value_counts().plot(kind = 'bar')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0ba872eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD/CAYAAAD/qh1PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzqCXpMIZ9JJUOINekgr3f8aRQlxKZDn3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1aukXNOV4nY",
        "colab_type": "code",
        "outputId": "639baea2-99ff-4b3d-8745-51723fa1558d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "\n",
        "pd.Series(train_y).value_counts().plot(kind = 'bar')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0ba7feac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD/CAYAAAD/qh1PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnEEvSZUz6CWpcga9JFXOoJekyv1/pXWq9AtRA5wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhMA1j7wnqSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Custom Model\n",
        "from tensorflow.python import keras\n",
        "from keras_radam import RAdam\n",
        "\n",
        "with strategy.scope():\n",
        "    inputs = model.inputs[:2]\n",
        "    dense = model.get_layer('NSP-Dense').output\n",
        "    outputs = keras.layers.Dense(units=20, activation='softmax')(dense)\n",
        "    \n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        RAdam(lr=LR),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'],\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmOLb7lWvDvl",
        "colab_type": "code",
        "outputId": "d85b2528-0a81-4566-a90c-f18dd2e1a0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#  Initialize Variables\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "sess = K.get_session()\n",
        "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
        "init_op = tf.variables_initializer(\n",
        "    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
        ")\n",
        "sess.run(init_op)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgP7bCQxrZpQ",
        "colab_type": "code",
        "outputId": "65052e46-2f99-44ed-bf33-dd2447a4e854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "# Fit\n",
        "\n",
        "model.fit(\n",
        "    train_x,\n",
        "    train_y,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "117/117 [==============================] - 62s 527ms/step - loss: 3.0176 - sparse_categorical_accuracy: 0.0704\n",
            "Epoch 2/7\n",
            "117/117 [==============================] - 23s 196ms/step - loss: 2.5561 - sparse_categorical_accuracy: 0.1997\n",
            "Epoch 3/7\n",
            "117/117 [==============================] - 23s 195ms/step - loss: 1.6576 - sparse_categorical_accuracy: 0.4726\n",
            "Epoch 4/7\n",
            "117/117 [==============================] - 23s 196ms/step - loss: 0.8934 - sparse_categorical_accuracy: 0.7141\n",
            "Epoch 5/7\n",
            "117/117 [==============================] - 23s 197ms/step - loss: 0.5291 - sparse_categorical_accuracy: 0.8329\n",
            "Epoch 6/7\n",
            "117/117 [==============================] - 23s 195ms/step - loss: 0.3508 - sparse_categorical_accuracy: 0.8900\n",
            "Epoch 7/7\n",
            "117/117 [==============================] - 23s 196ms/step - loss: 0.2527 - sparse_categorical_accuracy: 0.9173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0b304d048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBSba3vprlRD",
        "colab_type": "code",
        "outputId": "dbcfb5fb-3f6a-4c7e-a947-36335ce815bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# @title Predict\n",
        "\n",
        "predicts = model.predict(test_x, verbose=True).argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116/116 [==============================] - 1909s 16s/step\n",
            "116/116 [==============================] - 1909s 16s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1aps8prrCq",
        "colab_type": "code",
        "outputId": "ba8d3a1f-bdf7-44c5-eb16-223dfa7e492f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# @title Accuracy\n",
        "\n",
        "print(np.sum(test_y == predicts) / test_y.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8057650862068966\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}